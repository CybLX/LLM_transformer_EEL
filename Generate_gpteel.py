#%%
from src.vocab_and_tokenize.tokenizer import vocabulario
from src.the_model.wrapper import AutoregressiveWrapper
from src.Generate import Generator
import argparse
import torch
import os

def _parse_args() -> object:
    parser = argparse.ArgumentParser(
        description='LuAll trainer parser')
    
    parser.add_argument(
    '-cl',                          "--word_level",
                                    action  = 'store_true', 
                                    default = False,
                                    help    = "Indicates whether to process the input at the character level instead of the word level.")

    parser.add_argument(
    '-cu',                          "--no_cuda",
                                    action  = 'store_false', 
                                    default = True,
                                    help    = "Enables GPU acceleration for training if set to True.")
    
    parser.add_argument(
    '-st',                          "--no_save_texts",
                                    action  = 'store_false', 
                                    default = True,
                                    help    = "If present, indicates not to save the generated texts to a file.")
    
    parser.add_argument(
    '-ml',                          "--max_length",
                                    metavar = '',
                                    type    = int, 
                                    default = 100,
                                    help    = "Sets the maximum length of input sequences for the model.")

    parser.add_argument(
    '-nt',                          "--number_texts",
                                    metavar = '',
                                    type    = int, 
                                    default = 5,
                                    help    = "Specifies the number of sentences to be generated by the model.")
    
    parser.add_argument(
    '-sd',                          "--save_dir",
                                    metavar = '',
                                    type    = str,
                                    default = './generated_texts',
                                    help    = "Specifies the directory where the generated texts will be saved.")
    
    parser.add_argument(
    '-md',                          "--model_dir",
                                    metavar = '',
                                    type    = str,
                                    default = './modelos',
                                    help    = "Specifies the directory path where model checkpoints and outputs are saved.")


    args = parser.parse_args()
    return args

def handle_dirs(dirpath):
    if not os.path.exists(dirpath):
        os.makedirs(dirpath)



def main(args):

    # handle cuda
    print("Checking cuda", flush = True)
    if args.no_cuda:
        cuda = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        cuda = torch.device("cpu")

    print("Using CUDA: {}\n\n".format(torch.cuda.get_device_name()), flush = True)
    
    # handle dirs
    print("Creating saves directories", flush = True)
    

    mode = "/word" if args.word_level else "/char"


    if os.path.exists(args.model_dir):
        
        path = args.model_dir + mode
        
        # Inicia o vocabulario
        tokenizer = vocabulario()
        tokenizer.load_from_json(f"{path}/GPTeel_vocab.json")

        # Inicia o modelo
        model = AutoregressiveWrapper.load_checkpoint(path = f'{path}/GPTeel.pt', cuda =  cuda)

        # Gera o comentario
        generator = Generator(model, tokenizer)

        prompt = input("Insira o prompt: ")

        texts = []
        for i in range(0,args.number_texts):
            generated_text = generator.generate(cuda,
                max_tokens_to_generate= args.max_length,
                prompt= prompt,
                padding_token=tokenizer.lookup_token('<pad>')
            ).replace('<pad>', '')
            print(generated_text + "\n", flush=True)
            texts.append(generated_text)

        if args.no_save_texts:
            handle_dirs(args.save_dir)     
            handle_dirs(args.save_dir + mode)
            text_file = args.save_dir + mode + "/comentarios.txt"
            text_file = os.path.join(text_file)
            
            with open(text_file, 'w') as file:
                for string in texts:
                    file.write(f"{string}\n")
            print("Textos Salvos", flush=True)
        else:
            pass
    else:
        raise FileNotFoundError(f"The path {args.save_dir} does not exist.")


if __name__ == "__main__":
    args = _parse_args()
    main(args)
# %%
